{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getAllFeatures test:  passed!\n",
      "summariseFeatures test:  passed!\n",
      "17\n",
      "summariseClasses test: \n",
      "[[1.78664, 1.29407, 1.42938, 0.0, 0.0, 0.813071, 0.0, 0.0, 0.0, 0.0, 0.415276, 0.504283, 0.0, 0.00625724, 0.0, 0.571534, 0.859951], [0.0, 0.0, 0.0, 0.325211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.346812, 0.0818186, 0.0, 0.22692, 0.0, 0.0, 0.611511], [0.0537428, 0.0, 0.0, 0.351887, 0.604677, 0.0, 1.07561, 0.41141, 0.547717, 1.09836, 0.792746, 0.0, 0.890492, 0.0, 0.0, 0.574416, 0.337656]]\n",
      "[1.78664, 1.29407, 1.42938, 0.0, 0.0, 0.813071, 0.0, 0.0, 0.0, 0.0, 0.415276, 0.504283, 0.0, 0.00625724, 0.0, 0.571534, 0.859951]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-6e3d53633121>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"summariseClasses test: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m \u001b[0mclassSummaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummariseClasses\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mclassSummaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-180-6e3d53633121>\u001b[0m in \u001b[0;36msummariseClasses\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minstances\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0msummaries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassValue\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummariseFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0msummaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msummaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-180-6e3d53633121>\u001b[0m in \u001b[0;36msummariseFeatures\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msummariseFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetAllFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0msummaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-180-6e3d53633121>\u001b[0m in \u001b[0;36mgetAllFeatures\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmeasurement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[1;31m#print measurement, dataset[measurement]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[1;32mfor\u001b[0m \u001b[0mlistOfFeatures\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmeasurement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[1;31m#print listOfFeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlistOfFeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers, not list"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import glob\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import copy\n",
    "import random \n",
    "import math\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------#   \n",
    "#------------------------------------------CLASSIFIER CODE--------------------------------------------------------#\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#AUIntensity Classifier\n",
    "photoData = {}\n",
    "\n",
    "dictAuTranslation = {0 : \"AU01\", 1 : \"AU02\", 2 :\"AU04\", 3:\"AU05\", 4:\"AU06\",5:\"AU07\",6:\"AU09\",7:\"AU10\",8:\"AU12\",9:\"AU14\",10:\"AU15\",\n",
    "                     11:\"AU17\",12:\"AU20\",13:\"AU23\",14:\"AU25\",15:\"AU26\",16:\"AU28\",17:\"AU45\"}\n",
    "\n",
    "def getRoundedPhotoData():\n",
    "    traitFile = open(\"C:/Users/rrenv/Desktop/Level4Project/averageRatings.csv\", \"r\")\n",
    "    for line in traitFile:\n",
    "        line = line[:-1]\n",
    "        values = line.split(\",\")\n",
    "        traitValues = []\n",
    "        if (values[0][:12] not in photoData):\n",
    "            photoData[values[0][:12]] = []\n",
    "            for trait in values[1:]:\n",
    "                traitValues.append(round(float(trait)))\n",
    "            photoData[values[0][:12]].append(traitValues)\n",
    "    traitFile.close()\n",
    "    #print len(photoData)\n",
    "    filesToGoThrough = glob.glob(\"C:/Users/rrenv/Desktop/Level4Project/OpenFace_0.2_win_x64/data/outputFiles/*.pts\")\n",
    "    for file in filesToGoThrough:\n",
    "        auIntensities = []\n",
    "        auActivations = []\n",
    "        headPose = []\n",
    "        filename = file.split(\"/\")[-1][12:][:12]\n",
    "        currentFile = open(file, \"r\")\n",
    "        listOfLines = currentFile.readlines()\n",
    "        for i in range(0,3):\n",
    "            value=listOfLines[74].split(\" \")[i]\n",
    "            if (i == 2):\n",
    "                headPose.append(float(value[0:-1]))\n",
    "            else:\n",
    "                headPose.append(float(value))\n",
    "        photoData[filename].append(headPose)\n",
    "        for i in range(0,17):\n",
    "            value=listOfLines[82+i].split(\" \")[1]\n",
    "            auIntensities.append(float(value[0:-1]))\n",
    "        photoData[filename].append(auIntensities)\n",
    "        for i in range(0,18):\n",
    "            value=listOfLines[102+i].split(\" \")[1]\n",
    "            auActivations.append(float(value))\n",
    "        photoData[filename].append(auActivations)\n",
    "        currentFile.close()\n",
    "        \n",
    "#Split into Training and Testing\n",
    "\n",
    "def splitData(data, ratio):\n",
    "    trainingSize = int(len(data) * ratio)\n",
    "    trainSet = []\n",
    "    copyOfData = copy.copy(data)\n",
    "    while (len(trainSet) < trainingSize):\n",
    "        trainSet.append(copyOfData.pop(random.choice(copyOfData.keys())))\n",
    "    return [trainSet, copyOfData]\n",
    "\n",
    "#Separate Data by Class\n",
    "\n",
    "def assignOnScale(dataset, variable): #Variable will mean which of the 5 personality traits you are trying to classify\n",
    "    assigned = {}\n",
    "    for i in range(len(dataset)):\n",
    "        #print \"working with: \", dataset[i]\n",
    "        vector = dataset[i][0][variable]\n",
    "        if (vector not in assigned):\n",
    "            assigned[vector] = []\n",
    "        for j in range(1,len(dataset[i])):\n",
    "            assigned[vector].append(dataset[i][j])\n",
    "    return assigned\n",
    "\n",
    "#Hard coded for AU Intensities; easier for testing and time constraints as it's the most interesting\n",
    "\n",
    "def assignOnScaleModest(dataset): \n",
    "    assigned = {1 : [], 2: []}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i][0][2]\n",
    "        if vector >= 0:\n",
    "            assigned[2].append(dataset[i][2])\n",
    "        else:\n",
    "            assigned[1].append(dataset[i][2])\n",
    "    #print assigned\n",
    "    return assigned\n",
    "\n",
    "#Get Mean for each Attribute\n",
    "\n",
    "def getMean(feature):\n",
    "    return (sum(feature)/len(feature))\n",
    "\n",
    "#Get Standard Deviation\n",
    "\n",
    "def getStdDev(feature):\n",
    "    mean = getMean(feature)\n",
    "    variance = sum([pow(x-mean,2) for x in feature])/float(len(feature)-1)\n",
    "    return np.sqrt(variance)\n",
    "\n",
    "#Summarise Dataset\n",
    "\n",
    "def getAllFeatures(dataset): #parameter is a variable to choose either AUActivation, Intensity, or HeadPose\n",
    "    features = {}\n",
    "    for measurement in dataset:\n",
    "        #print measurement, dataset[measurement]\n",
    "        for listOfFeatures in measurement:\n",
    "            #print listOfFeatures\n",
    "            for x in range (0, len(listOfFeatures)):\n",
    "                if dictAuTranslation[x] in features:\n",
    "                    features[dictAuTranslation[x]].append(listOfFeatures[x])\n",
    "                else:\n",
    "                    features[dictAuTranslation[x]] = []\n",
    "                    features[dictAuTranslation[x]].append(listOfFeatures[x])\n",
    "    #print features\n",
    "    return features\n",
    "\n",
    "getRoundedPhotoData()\n",
    "trainSet, testSet = splitData(photoData, 0.01)\n",
    "trainSetfeatures = assignOnScaleModest(trainSet)\n",
    "print \"getAllFeatures test: \", 'passed!'\n",
    "#getAllFeatures(trainSetfeatures)\n",
    "\n",
    "\n",
    "    \n",
    "def summariseFeatures(dataset):\n",
    "    features = getAllFeatures(dataset)\n",
    "    summaries = {}\n",
    "    print len(features)\n",
    "    for x in range(0,len(features)):\n",
    "        mean = getMean(features[dictAuTranslation[x]])\n",
    "        stdDev = getStdDev(features[dictAuTranslation[x]])\n",
    "        summaries[dictAuTranslation[x]] = []\n",
    "        summaries[dictAuTranslation[x]].append(float(mean))\n",
    "        summaries[dictAuTranslation[x]].append(float(stdDev))\n",
    "    return summaries\n",
    "\n",
    "print \"summariseFeatures test: \", 'passed!'\n",
    "featureSummaries = summariseFeatures(trainSetfeatures)\n",
    "#print featureSummaries\n",
    "#Summarise Attributes by Class\n",
    "\n",
    "def summariseClasses(dataset):\n",
    "    assigned = assignOnScaleModest(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in assigned.iteritems():\n",
    "        print instances\n",
    "        for instance in instances:\n",
    "            print instance\n",
    "            summaries[classValue] = summariseFeatures(instances)\n",
    "    print summaries\n",
    "    return summaries\n",
    "\n",
    "print \"summariseClasses test: \"\n",
    "classSummaries = summariseClasses(trainSet)\n",
    "print classSummaries\n",
    "\n",
    "#Make Predictions based on Probabilities\n",
    "\n",
    "#Gaussian Probablilty (probability of a given value given mean and standard deviation)\n",
    "\n",
    "def findprobability(value, mean, stdev): # value is what we're looking for the probability of\n",
    "    exponent = math.exp(-(math.pow(value-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1/(math.sqrt(2*math.pi)*stdev))*exponent\n",
    "\n",
    "#Apply to classes in our data\n",
    "\n",
    "def calculateClassProbabilities(classSummaries, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.iteritems():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(0, len(classSummaries)):\n",
    "            mean, stdev = classSummaries\n",
    "            x = inputVector[i]\n",
    "            if (stdev != 0):\n",
    "                probabilities[classValue] *= findprobability(x, mean, stdev)\n",
    "    return probabilities\n",
    "    \n",
    "getRoundedPhotoData()\n",
    "trainSet, testSet = splitData(photoData, 0.01)\n",
    "trainSetfeatures = assignOnScaleModest(trainSet)\n",
    "#print trainSetfeatures\n",
    "#print len(trainSet)\n",
    "#for feature, measurements in trainSetfeatures.iteritems():\n",
    "#    for measurement in measurements:\n",
    "#        print feature, ': ', len(measurements[1])\n",
    "#features = getAllFeatures(trainSet, 2)\n",
    "inputVector = testSet[random.choice(testSet.keys())][2]\n",
    "\n",
    "print 'input vector: ', inputVector\n",
    "calculateClassProbabilities(classSummaries, inputVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
